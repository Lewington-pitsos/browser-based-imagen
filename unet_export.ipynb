{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97423763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "C:\\Python310\\lib\\site-packages\\beartype\\_util\\hint\\pep\\utilpeptest.py:345: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.List[str] deprecated by PEP 585 scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". See this discussion for further details and alternatives:\n",
      "    https://github.com/beartype/beartype#pep-585-deprecations\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
    "from imagen_pytorch.data import Dataset\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from imagen_pytorch.t5 import t5_encode_text\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fafb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Make sure all instances of expm1(x) are purged from the source code (and replaced with a simple exp(x) - 1)\n",
    "# expm1 is not supported by onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c737c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(\n",
    "    dim = 128, # the \"Z\" layer dimension, i.e. the number of filters the outputs to the first layer\n",
    "    cond_dim = 256,\n",
    "    dim_mults = (1, 2, 4), # the channel dimensions inside the model (multiplied by dim)\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True),\n",
    "    layer_cross_attns = (False, True, True)\n",
    ")\n",
    "\n",
    "imagen = Imagen(\n",
    "    unets = unet,\n",
    "    image_sizes = 32,\n",
    "    timesteps = 1000,\n",
    "    cond_drop_prob = 0.1,\n",
    "    dynamic_thresholding=False\n",
    ")\n",
    "\n",
    "\n",
    "class ImagenOnnx(torch.nn.Module):\n",
    "    def __init__(self, unet, imagen):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "        self.imagen = imagen\n",
    "\n",
    "    def sample(self, text_embeds, text_mask, cond_scale,  device, use_tqdm=True):\n",
    "        batch_size = text_embeds.shape[0]\n",
    "        noise_scheduler = self.imagen.noise_schedulers[0]\n",
    "        img = torch.randn((batch_size, self.imagen.sample_channels[0], self.imagen.image_sizes[0], self.imagen.image_sizes[0]), device = device)\n",
    "        timesteps = noise_scheduler.get_sampling_timesteps(batch_size, device = device)\n",
    "\n",
    "        for times, times_next in tqdm(timesteps, desc='sampling loop time step', total=len(timesteps), disable=not use_tqdm):       \n",
    "\n",
    "            img, _ = self.imagen.p_sample(\n",
    "                self.unet,\n",
    "                img,\n",
    "                times,\n",
    "                t_next = times_next,\n",
    "                text_embeds = text_embeds,\n",
    "                text_mask = text_mask,\n",
    "                cond_scale = cond_scale,\n",
    "                noise_scheduler = noise_scheduler,\n",
    "                pred_objective = self.imagen.pred_objectives[0],\n",
    "                dynamic_threshold = False\n",
    "            )\n",
    "\n",
    "        img.clamp_(-1., 1.)\n",
    "\n",
    "        unnormalize_img = self.imagen.unnormalize_img(img)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def forward(self, img, text_embeds, text_mask, times, times_next, cond_scale):\n",
    "        return self.imagen.p_sample(\n",
    "            self.unet,\n",
    "            img,\n",
    "            times,\n",
    "            t_next = times_next,\n",
    "            text_embeds = text_embeds,\n",
    "            text_mask = text_mask,\n",
    "            cond_scale = cond_scale,\n",
    "            noise_scheduler=imagen.noise_schedulers[0],\n",
    "            pred_objective = imagen.pred_objectives[0],\n",
    "            dynamic_threshold = False\n",
    "        )\n",
    "    \n",
    "u = U(unet, imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0e50ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u.sample(torch.rand(1, 10, 768), torch.ones(1, 10, dtype=bool), 1., device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c57b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# u.forward(torch.rand(1, 3, 32, 32),  torch.rand(1, 27, 786), torch.rand(1, 27, 786), torch.Tensor([0.5]), torch.Tensor([0.56]), torch.Tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61782e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\imagen_pytorch\\imagen_pytorch.py:2006: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert not (cond_scale != 1. and not self.can_classifier_guidance), 'imagen was not trained with conditional dropout, and thus one cannot use classifier free guidance (cond_scale anything other than 1)'\n",
      "C:\\Python310\\lib\\site-packages\\einops\\einops.py:204: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  inferred_length: int = length // known_product\n",
      "C:\\Python310\\lib\\site-packages\\imagen_pytorch\\imagen_pytorch.py:1580: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if remainder > 0:\n",
      "C:\\Python310\\lib\\site-packages\\imagen_pytorch\\imagen_pytorch.py:1584: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if remainder > 0:\n",
      "C:\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2515: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  _verify_batch_size([input.size(0) * input.size(1) // num_groups, num_groups] + list(input.size()[2:]))\n",
      "C:\\Python310\\lib\\site-packages\\einops\\packing.py:149: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  -1 if -1 in p_shape else prod(p_shape)\n",
      "C:\\Python310\\lib\\site-packages\\einops\\packing.py:154: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if n_unknown_composed_axes > 1:\n",
      "C:\\Python310\\lib\\site-packages\\einops\\packing.py:166: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if n_unknown_composed_axes == 0:\n",
      "C:\\Python310\\lib\\site-packages\\imagen_pytorch\\imagen_pytorch.py:1482: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if cond_scale == 1:\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    u, \n",
    "    (torch.rand(1, 3, 32, 32),  torch.rand(1, 27, 768), torch.ones(1, 27, dtype=bool), torch.Tensor([0.5]), torch.Tensor([0.56]), torch.Tensor([1.])), \n",
    "    \"unet.onnx\", \n",
    "    input_names=['image', 'text_embeds', 'text_mask', 'timestep', 'time_next', 'cond_scale'], \n",
    "    output_names=['prediction'],\n",
    "    dynamic_axes={\n",
    "        'image': {0: 'batch_size'},\n",
    "        'text_embeds': {0: 'batch_size', 1: 'n_tokens'},\n",
    "        'text_mask': {0: 'batch_size', 1: 'n_tokens'},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26c059c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
