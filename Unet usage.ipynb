{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b586b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
    "from imagen_pytorch.t5 import t5_encode_text\n",
    "from imagen_pytorch.data import Dataset\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from einops import repeat\n",
    "import torchvision.transforms as T\n",
    "from torch.special import expm1\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a3d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5a8964",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(\n",
    "    dim = 128, # the \"Z\" layer dimension, i.e. the number of filters the outputs to the first layer\n",
    "    cond_dim = 256,\n",
    "    dim_mults = (1, 2, 4), # the channel dimensions inside the model (multiplied by dim)\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True),\n",
    "    layer_cross_attns = (False, True, True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cd8996",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_mults = (1, 2, 4, 8)\n",
    "\n",
    "unet = Unet(\n",
    "  dim = 128, # the \"Z\" layer dimension, i.e. the number of filters the outputs to the first layer\n",
    "  cond_dim = 128,\n",
    "  dim_mults = dim_mults, # the channel dimensions inside the model (multiplied by dim)\n",
    "  num_resnet_blocks = 3,\n",
    "  layer_attns = (False,) + (True,) * (len(dim_mults) - 1),\n",
    "  layer_cross_attns = (False,) + (True,) * (len(dim_mults) - 1)\n",
    ")\n",
    "\n",
    "imagen = Imagen(\n",
    "    unets = unet,\n",
    "    image_sizes = 32,\n",
    "    timesteps = 250,\n",
    "    cond_drop_prob = .1\n",
    ").cuda()\n",
    "\n",
    "trainer = ImagenTrainer(imagen, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0932aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen = Imagen(\n",
    "    unets = unet,\n",
    "    image_sizes = 32,\n",
    "    timesteps = 1000,\n",
    "    cond_drop_prob = 0.1\n",
    ").cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7fb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = imagen.sample(texts = [\n",
    "#     'a whale breaching from afar',\n",
    "#     # 'young girl blowing out candles on her birthday cake',\n",
    "#     # 'fireworks with blue and green sparkles'\n",
    "# ], cond_scale = 3)\n",
    "\n",
    "# img = T.ToPILImage()(images[0])\n",
    "# img.save(\"whale.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b78d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "encodings, mask = t5_encode_text(['a whale breaching from afar'], return_attn_mask=True)\n",
    "print(encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4262f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(imagen, unet, cond_scale, text_embeds, text_mask, device, use_tqdm=True):\n",
    "    batch_size = text_embeds.shape[0]\n",
    "    noise_scheduler = imagen.noise_schedulers[0]\n",
    "    img = torch.randn((batch_size, imagen.sample_channels[0], imagen.image_sizes[0], imagen.image_sizes[0]), device = device)\n",
    "    timesteps = noise_scheduler.get_sampling_timesteps(batch_size, device = device)\n",
    "        \n",
    "    for times, times_next in tqdm(timesteps, desc='sampling loop time step', total=len(timesteps), disable=not use_tqdm):       \n",
    "        \n",
    "        img, _ = imagen.p_sample(\n",
    "            unet,\n",
    "            img,\n",
    "            times,\n",
    "            t_next = times_next,\n",
    "            text_embeds = text_embeds,\n",
    "            text_mask = text_mask,\n",
    "            cond_scale = cond_scale,\n",
    "            noise_scheduler = noise_scheduler,\n",
    "            pred_objective = imagen.pred_objectives[0],\n",
    "            dynamic_threshold = imagen.dynamic_thresholding\n",
    "        )\n",
    "        \n",
    "    img.clamp_(-1., 1.)\n",
    "\n",
    "    unnormalize_img = imagen.unnormalize_img(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae6cbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sampling loop time step: 100%|█████████████████████████████████████████████████████| 1000/1000 [00:39<00:00, 25.52it/s]\n"
     ]
    }
   ],
   "source": [
    "out = sample(\n",
    "    imagen, \n",
    "    unet, \n",
    "    cond_scale=1., \n",
    "    text_embeds=encodings,\n",
    "    text_mask=mask,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e32c695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = T.ToPILImage()(out[0])\n",
    "img.save(\"whale7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f912bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @torch.jit.script\n",
    "# def beta_linear_log_snr(t):\n",
    "#     return -torch.log(expm1(1e-4 + 10 * (t ** 2)))\n",
    "\n",
    "# def log_snr_to_alpha_sigma(log_snr):\n",
    "#     return torch.sqrt(torch.sigmoid(log_snr)), torch.sqrt(torch.sigmoid(-log_snr))\n",
    "\n",
    "#     def q_posterior(self, x_start, x_t, t, *, t_next = None):\n",
    "#         \"\"\" https://openreview.net/attachment?id=2LdBqxc1Yv&name=supplementary_material \"\"\"\n",
    "#         log_snr = self.log_snr(t)\n",
    "#         log_snr_next = self.log_snr(t_next)\n",
    "#         log_snr, log_snr_next = map(partial(right_pad_dims_to, x_t), (log_snr, log_snr_next))\n",
    "\n",
    "#         alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "#         alpha_next, sigma_next = log_snr_to_alpha_sigma(log_snr_next)\n",
    "\n",
    "#         # c - as defined near eq 33\n",
    "#         c = -expm1(log_snr - log_snr_next)\n",
    "#         posterior_mean = alpha_next * (x_t * (1 - c) / alpha + c * x_start)\n",
    "\n",
    "#         # following (eq. 33)\n",
    "#         posterior_variance = (sigma_next ** 2) * c\n",
    "#         posterior_log_variance_clipped = log(posterior_variance, eps = 1e-20)\n",
    "#         return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "    \n",
    "# def normalize_neg_one_to_one(img):\n",
    "#     return img * 2 - 1\n",
    "\n",
    "# def unnormalize_zero_to_one(normed_img):\n",
    "#     return (normed_img + 1) * 0.5\n",
    "\n",
    "# def get_sampling_timesteps(batch, num_timesteps, device):\n",
    "#     times = torch.linspace(1., 0., num_timesteps + 1, device = device)\n",
    "#     times = repeat(times, 't -> b t', b = batch)\n",
    "#     times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "#     times = times.unbind(dim = -1)\n",
    "#     return times\n",
    "\n",
    "# def right_pad_dims_to(x, t):\n",
    "#     padding_dims = x.ndim - t.ndim\n",
    "#     if padding_dims <= 0:\n",
    "#         return t\n",
    "#     return t.view(*t.shape, *((1,) * padding_dims))\n",
    "\n",
    "# def predict_start_from_noise(self, x_t, t, noise):\n",
    "#     log_snr = beta_linear_log_snr(t)\n",
    "#     log_snr = right_pad_dims_to(x_t, log_snr)\n",
    "#     alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "#     return (x_t - sigma * noise) / alpha.clamp(min = 1e-8)\n",
    "\n",
    "# def predict_start_from_v(self, x_t, t, v):\n",
    "#     log_snr = beta_linear_log_snr(t)\n",
    "#     log_snr = right_pad_dims_to(x_t, log_snr)\n",
    "#     alpha, sigma = log_snr_to_alpha_sigma(log_snr)\n",
    "#     return alpha * x_t - sigma * v\n",
    "\n",
    "\n",
    "# def get_sampling_timesteps(batch, num_timesteps, device):\n",
    "#     times = torch.linspace(1., 0., num_timesteps + 1, device = device)\n",
    "#     times = repeat(times, 't -> b t', b = batch)\n",
    "#     times = torch.stack((times[:, :-1], times[:, 1:]), dim = 0)\n",
    "#     times = times.unbind(dim = -1)\n",
    "#     return times\n",
    "\n",
    "\n",
    "#         pred = unet.forward_with_cond_scale(\n",
    "#             img, \n",
    "#             beta_linear_log_snr(t), \n",
    "#             text_embeds = text_embeds, \n",
    "#             text_mask = text_mask,\n",
    "#             cond_scale = cond_scale,\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#         if pred_objective == 'noise':\n",
    "#             x_start = predict_start_from_noise(x, t = times, noise = pred)\n",
    "#         elif pred_objective == 'x_start':\n",
    "#             x_start = pred\n",
    "#         elif pred_objective == 'v':\n",
    "#             x_start = predict_start_from_v(x, t = t, v = pred)\n",
    "#         else:\n",
    "#             raise ValueError(f'unknown objective {pred_objective}')\n",
    "\n",
    "        \n",
    "#         if dynamic_threshold:\n",
    "#             # following pseudocode in appendix\n",
    "#             # s is the dynamic threshold, determined by percentile of absolute values of reconstructed sample per batch element\n",
    "#             s = torch.quantile(\n",
    "#                 rearrange(x_start, 'b ... -> b (...)').abs(),\n",
    "#                 self.dynamic_thresholding_percentile,\n",
    "#                 dim = -1\n",
    "#             )\n",
    "\n",
    "#             s.clamp_(min = 1.)\n",
    "#             s = right_pad_dims_to(x_start, s)\n",
    "#             x_start = x_start.clamp(-s, s) / s\n",
    "#         else:\n",
    "#             x_start.clamp_(-1., 1.)\n",
    "        \n",
    "        \n",
    "#         (model_mean, _, model_log_variance) = q_posterior(x_start = x_start, x_t = x, t = t, t_next = t_next)\n",
    "        \n",
    "#         noise = torch.randn_like(x)\n",
    "            \n",
    "#         is_last_sampling_timestep = (times_next == 0) \n",
    "#         nonzero_mask = (1 - is_last_sampling_timestep.float()).reshape(batch_size, *((1,) * (len(x.shape) - 1)))\n",
    "                    \n",
    "#         img = model_mean + nonzero_mask * (0.5 * model_log_variance).exp() * noise\n",
    "        \n",
    "#     img.clamp_(-1., 1.)\n",
    "    \n",
    "    \n",
    "#         # finally un-normalize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
